\chapter{実験と評価}
\label{chap:experiments}

\section{実験設定}

\subsection{データセット}
本研究では、提案手法の有効性と汎化性能を検証するために、学習用として大規模な野生動物データセット、評価用として実際の動物園で撮影された監視映像データセットの2種類を使用した。

\subsubsection{学習用データセット: Animal Kingdom}
学習には、多様な動物種と行動を含む大規模データセットであるAnimal Kingdomを使用した。このデータセットは850種類以上の動物と140種類以上の行動クラスを含んでおり、多様な環境下で撮影されているため、汎用的な特徴表現の学習に適している。
本研究では、実験の対象を哺乳類（Mammals）に限定し、以下の基準でデータのフィルタリングを行った。
\begin{itemize}
  \item 100以上の動画サンプルが存在する行動クラスのみを選定。
  \item 各動画には単一の動物種のみが映っていること。
  \item 各クリップの長さが16フレーム以上であること。
  \item 複数の個体が異なる行動をとっている動画は除外する。
\end{itemize}
結果として、「Walking」「Eating」「Running」などを含む主要な行動クラスを用いてモデルの学習を行った。

\subsubsection{評価用データセット: シロクマ監視映像}
提案手法の未知の環境に対する適応能力を評価するため、札幌市円山動物園のホッキョクグマ館で撮影された監視映像を使用した。
データは2020年8月30日に固定カメラを用いて撮影されたもので、解像度は$368 \times 640$ピクセルである。Animal Kingdomのようなドキュメンタリー映像とは異なり、照明条件の変化やカメラのブレ、複雑な背景など、実環境特有のノイズを含んでいる。
行動ラベルは飼育員の観察記録に基づき、以下のクラスについて、個体が単一の行動を継続している30秒間のセグメントを手動で抽出した。
\begin{itemize}
  \item \textbf{基本行動}: Sleeping（睡眠）、Swimming（遊泳）、Walking（歩行）、Keeping still（静止）
  \item \textbf{常同行動 (Stereotypic behavior)}: 動物福祉の観点で重要な指標となる、ペーシング（常同歩行）などの反復的な異常行動。
\end{itemize}

\subsection{実装詳細とハイパーパラメータ}
外見特徴の抽出にはImageNetで事前学習されたVideoMAEを、動作特徴の抽出にはKinetics-400で事前学習されたX3Dを使用した。これらのバックボーンネットワークの重みは固定し、特徴抽出器として利用した。
オプティカルフローの抽出にはRAFTを用い、隣接フレーム間の密なフローを推定した。

学習の安定性を確保するため、ハイパーパラメータの最適化にはOptunaを使用した。具体的には、Animal Kingdomの検証セットにおけるARI（Adjusted Rand Index）を最大化するように、トリプレット損失のマージン $m$ を $[0.05, 0.5]$ の範囲で、敵対的損失の重み係数 $\lambda$ を $[0.01, 1.0]$ の範囲で探索した。

\section{評価指標}
学習された埋め込み空間において、行動クラスがどの程度適切に分離されているかを定量的に評価するため、抽出された特徴ベクトルに対してKMeans++によるクラスタリングを適用した。評価指標には以下の2つを採用した。

\begin{enumerate}
  \item \textbf{ARI (Adjusted Rand Index)}: クラスタリング結果と正解ラベルの類似度を測定する指標であり、偶然による一致を補正したもの。値は$[-1, 1]$の範囲をとり、1に近いほど高い性能を示す。
  \item \textbf{NMI (Normalized Mutual Information)}: クラスタリング結果と正解ラベルの相互情報量を正規化したもの。クラスサイズが不均衡な場合でも安定した評価が可能である。
\end{enumerate}

また、定性的な評価として、t-SNEを用いて特徴空間を2次元に圧縮・可視化し、クラス間の分離や重なりを視覚的に確認した。

\section{実験結果}

\subsection{定量評価}
札幌市円山動物園のシロクマデータセット（未知のドメイン）に対するクラスタリング性能の比較結果を表\ref{tab:results}に示す。比較対象として、RGBのみを用いたモデル、オプティカルフローのみを用いたモデル、敵対的学習を行わないGated Fusionモデルを設定した。

\begin{table}[htbp]
  \centering
  \caption{シロクマデータセットに対する各手法のクラスタリング性能比較 (ARIおよびNMI)}
  \label{tab:results}
  \begin{tabular}{lcc}
    \hline
    手法 & ARI & NMI \\
    \hline \hline
    RGB Only (Appearance) & 0.093 & 0.278 \\
    Optical Flow Only (Motion) & 0.557 & 0.539 \\
    Gated Fusion (Proposed w/o Adv) & 0.615 & 0.622 \\
    \textbf{Adversarial Gated Fusion (Proposed)} & \textbf{0.742} & \textbf{0.728} \\
    \hline
  \end{tabular}
\end{table}

表\ref{tab:results}より、以下の傾向が確認された。
まず、RGB情報のみを用いた場合、ARIは0.093と極めて低い値にとどまった。これは、学習データ（野生動物のドキュメンタリー映像）と評価データ（動物園の檻の中）の背景や環境が大きく異なるため、モデルが行動そのものではなく背景情報に過学習してしまったことによると考えられる。
一方、オプティカルフローのみを用いた場合はARI 0.557と大幅な性能向上が見られた。これは、動作情報が動物種や背景の色に依存しにくく、ドメイン間のギャップに対して頑健であることを示唆している。

さらに、Gated Fusionによって両者を統合することでARIは0.615まで向上し、マルチモーダル化の有効性が確認された。
最も重要な点として、提案手法である敵対的学習を導入したモデル（Adversarial Gated Fusion）は、ARI 0.742、NMI 0.728という最高の性能を達成した。これは、敵対的学習によって種固有の特徴（シロクマ特有の外見など）が抑制され、純粋な行動の特徴に基づいた埋め込み空間が形成されたためであると考えられる。

\subsection{定性評価 (可視化)}
図\ref{fig:tsne}（別途挿入）に、各モデルによって学習された特徴空間のt-SNE可視化結果を示す。
RGBのみのモデルでは、クラスごとのクラスタが崩れており、多くのサンプルが混在している様子が確認できる。これに対し、提案手法（Adversarial Gated Fusion）では、「Swimming」や「Walking」などの各行動クラスが明確に分離されたクラスタを形成しており、クラス間の境界も明瞭である。特に、動物福祉の観点で重要となる「Stereotypic behavior（常同行動）」のクラスタも他の行動と明確に区別されており、異常検知への応用可能性を示唆している。

\section{考察と限界}

\subsection{ドメイン適応における動作情報の重要性}
実験結果より、ドメインシフト（学習データとテストデータの環境差）が大きい場合、RGBによる外見情報はノイズとなりやすく、オプティカルフローによる動作情報が支配的な役割を果たすことが明らかになった。しかし、動作情報だけでは静止画的な文脈（例：食事中の姿勢など）を取りこぼす可能性があるため、Gated Fusionによる適応的な統合が性能向上に寄与したと考えられる。

\subsection{敵対的学習による種不変性の獲得}
敵対的学習を導入したモデルがベースラインを大きく上回ったことは、提案手法が「種に依存しない行動表現」の学習に成功していることを裏付けている。種識別器を騙すようにエンコーダを学習させることで、特定種（この場合はシロクマ）に特化した特徴が削ぎ落とされ、結果として未知の種に対しても汎用的な特徴空間が構築されたと言える。

\subsection{本手法の限界と課題}
一方で、いくつかの課題も残されている。
第一に、背景の動的ノイズの影響である。オプティカルフローは動物の動きだけでなく、背景の揺れやカメラノイズも拾ってしまうため、これらが行動特徴として誤学習される場合がある。より高度な背景差分技術との併用が望まれる。
第二に、複数個体の対応である。本実験では単一個体の映像に限定したが、実際の飼育環境では複数個体が同時に異なる行動をとる場合がある。個体追跡（Tracking）と行動認識を組み合わせたフレームワークへの拡張が今後の課題である。