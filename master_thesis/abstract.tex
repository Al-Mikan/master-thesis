\chapter*{概要}
本研究では，動物種および撮影環境の多様性に頑健な動物行動認識を実現するため，
マルチモーダル表現学習に基づく共有表現空間の構築手法を提案する．
動物行動認識は，動物園における個体管理や福祉評価を支援する重要な技術である．
しかし，従来手法の多くは膨大な行動ラベル付きデータを必要とし，
未知の動物種や環境への適用が困難であるという課題があった．

そこで本研究では，RGB 映像から得られる外観情報と，
オプティカルフロー（光フロー）に基づく運動情報を統合する
マルチモーダル表現学習手法を設計した．
各モダリティから抽出された特徴を
Gated Fusion に基づく統合機構により適応的に統合することで，
行動に対して判別的な表現空間を形成する．
さらに，獲得される表現から動物種固有のバイアスを除去するため，
種分類器を用いた敵対的学習を導入し，
動物種に依存しにくい汎用的な行動特徴の獲得を目指す．

提案手法の有効性を検証するため，
大規模動物行動データセットを用いて学習を行い，
未知環境で撮影された動物園のシロクマ映像に対して評価を行った．
クラスタリング指標を用いた評価の結果，
提案手法は単一モダリティに基づく手法と比較して，
動物種や環境の変化に対して頑健な行動表現を獲得できることを示した．

本研究の成果は，アノテーションコストを抑制しつつ，
多様な実環境へ適用可能な動物行動認識システムの実現に寄与するものである．
